{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "# Pretty progress bar (notebook version)\n",
    "from tqdm import tqdm_notebook as progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicer plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = \"18\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard method of using an environment varialble to controle the GPUs available (it would work with any CUDA code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Force only first GPU (P100 GPU) on Goofy\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "# This would be just the K40s:\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"1,2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put. If you have multiple GPU support, this still remains `cuda:0`, oddly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(i, torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "name = 'Aug_01_75000_2layer'\n",
    "data = '/data/schreihf/PvFinder/July_31_75000.npz'\n",
    "output = Path('Aug_01_75000_2layer')\n",
    "batch = 32\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the directory with the model\n",
    "definitions to the path so we can import it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collectdata import collect_data\n",
    "from loss import Loss\n",
    "from training import trainNet\n",
    "from models import SimpleCNN2Layer as Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, _ = collect_data(\n",
    "    data, 55_000, 10_000,\n",
    "    verbose=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "loss_fn = Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I currently have DataParallel as part of Model. It's probably the wrong place to put it, and it makes the model code more complicated. I may move it back here soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The body of this loop runs once per epoch. Results is a named tuple of values (loss per epoch for training and validation, time each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a pretty progress bar (any iterator can be given for epochs)\n",
    "progress = progress_bar(range(n_epochs), dynamic_ncols=True)\n",
    "\n",
    "# Run the epochs, using progress instead of range(n_epochs)\n",
    "for results in trainNet(model, dataset_train, dataset_val,\n",
    "                            loss_fn, batch, progress,\n",
    "                            learning_rate=learning_rate, verbose=False):\n",
    "        \n",
    "    # Pretty print a description\n",
    "    progress.set_postfix(train=results.cost[-1], val=results.val[-1])\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{results.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(output / f'{name}_stats.npz',\n",
    "         cost = np.array(results.cost),\n",
    "         val = np.array(results.val),\n",
    "         time = np.array(results.time)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot final details\n",
    "\n",
    "Who doesn't like pretty pictures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a pretty progress bar (any iterator can be given for epochs)\n",
    "progress = progress_bar(range(n_epochs), dynamic_ncols=True)\n",
    "\n",
    "# Run the epochs, using progress instead of range(n_epochs)\n",
    "for results in trainNet(model, dataset_train, dataset_val,\n",
    "                            loss_fn, batch, progress,\n",
    "                            learning_rate=learning_rate, verbose=False):\n",
    "        \n",
    "    # Pretty print a description\n",
    "    progress.set_postfix(train=results.cost[-1], val=results.val[-1])\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{results.epoch}.pyt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
